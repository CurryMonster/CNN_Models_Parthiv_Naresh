{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_Model_2019_August_Parthiv.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ParthivNaresh/CNN_Models_Parthiv_Naresh/blob/Practice%2FInceptionModel/CNN_Model_2019_August_Parthiv.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veWINm4gIr0V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install -U -q PyDrive\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from shutil import move\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from google.colab import auth\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.python.keras.utils import plot_model\n",
        "from tensorflow.python.keras.layers import Input\n",
        "from tensorflow.python.keras.optimizers import SGD, RMSprop\n",
        "from tensorflow.python.keras.layers.core import Dense, Flatten\n",
        "from tensorflow.python.keras.layers.convolutional import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "\n",
        "import tensorflow.contrib.eager as tfe\n",
        "\n",
        "tf.enable_eager_execution()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCMagAyQLlB3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7HYwNH4YbVK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "zip_data_file = \"https://s3-ap-southeast-1.amazonaws.com/he-public-data/DL%23+Beginner.zip\"\n",
        "zip_extract_location = \"/content/drive/My Drive/\"\n",
        "\n",
        "google_drive_location = \"/content/drive/My Drive/CNN_Project_1_Animals_Data\"\n",
        "\n",
        "data_directory = google_drive_location + \"/data/\"\n",
        "training_directory = google_drive_location + \"/train/\"\n",
        "testing_directory = google_drive_location + \"/test/\"\n",
        "predicting_directory = google_drive_location + \"/predict/\"\n",
        "labels_directory = google_drive_location + \"/animals_labels_train.csv\"\n",
        "visualizations = google_drive_location + '/Visualizations/'\n",
        "\n",
        "callback_cutoff_accuracy = 0.6\n",
        "\n",
        "data = pd.read_csv(labels_directory).rename(columns={'Image_id':'image_id','Animal':'animal'})\n",
        "data['animal'] = data.animal.str.replace('\\+', ' ')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlhmxkpUN2q3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "This data splitting class assumes that the data is initially presented in one folder\n",
        "and has already been shuffled.\n",
        "This class splits the data into a training and testing set with a ratio of 80% training\n",
        "and 20% testing.\n",
        "Categorization of the data into subfolders based on their labels is done in \n",
        "categorize_data().\n",
        "'''\n",
        "\n",
        "class split_data_training_test():\n",
        "    \n",
        "    def __init__(self, data_path):\n",
        "        self.data_path = data_path\n",
        "        self.all_the_data = []\n",
        "        for image_id in os.listdir(self.data_path):\n",
        "            if os.path.isfile(self.data_path + image_id):\n",
        "                self.all_the_data.append(image_id)\n",
        "        \n",
        "        self.train_list = train_test_split(self.all_the_data, train_size = 0.8, shuffle=False)[0]\n",
        "        self.test_list = train_test_split(self.all_the_data, train_size = 0.8, shuffle=False)[1]\n",
        "        print(str(len(self.train_list)) + \" images placed in the training set\")\n",
        "        print(str(len(self.test_list)) + \" images placed in the test set\")\n",
        "        #print(self.train_list[0:5])\n",
        "        #print(self.test_list[0:5])\n",
        "        \n",
        "    def move_training_to(self, train_path):\n",
        "        self.train_path = train_path\n",
        "        \n",
        "        for train_name in self.train_list:\n",
        "            move(self.data_path + train_name,self.train_path)\n",
        "        \n",
        "    def move_test_to(self, test_path):\n",
        "        self.test_path = test_path\n",
        "        \n",
        "        for test_name in self.test_list:\n",
        "            move(self.data_path + test_name,self.test_path)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2HF_GGN-9Ca",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "This categorization class assumes that the data has been presented in the following format:\n",
        "1 csv file with all the image ids in one column and their corresponding labels in another\n",
        "2 subfolders (training and testing) that hold a series of images with their file names as their image ids\n",
        "It will then create a set of folders within the training and testing folders corresponding to all\n",
        "unique labels from the csv file, and will move the images in the training and testing folders\n",
        "into their respective subfolders based on how they have been labeled in the csv file.\n",
        "This will make it easier to use the data in image generators later on.\n",
        "'''\n",
        "\n",
        "class categorize_data():\n",
        "  \n",
        "  # Initializes the distinct categories in the animal column\n",
        "  def __init__(self, data):\n",
        "    self.data = data\n",
        "    self.animal_categories = list(self.data.animal.unique())\n",
        "    \n",
        "  def in_directory(self, directory):\n",
        "    self.directory = directory\n",
        "    \n",
        "    # Makes a sub-directory for every animal in the specified directory\n",
        "    for animal in self.animal_categories:\n",
        "        if not os.path.exists(self.directory + animal):\n",
        "            os.mkdir(self.directory + animal)\n",
        "    \n",
        "    # Iterates through every file in the specified directory\n",
        "    # and finds the same file name in the csv with its\n",
        "    # relevant animal category and moves it to that animal folder\n",
        "    for image_id in os.listdir(self.directory):\n",
        "        if os.path.isfile(self.directory + image_id):\n",
        "            # Finds the row number that matches the current image-id in the dataframe\n",
        "            row = self.data.loc[self.data['image_id'] == image_id]\n",
        "            # iloc is needed to identify the value by INDEX\n",
        "            animal = row['animal'].iloc[0]\n",
        "            self.this_file = self.directory + image_id\n",
        "            self.destination = self.directory + \"\\\\\" + animal + \"\\\\\"\n",
        "            # Moves the image to the appropriate animal folder\n",
        "            move(self.this_file, self.destination)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLYwVuymMuYz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "This class assumes that all the data has been moved into appropriately labeled\n",
        "subfolders in the training or testing folders.\n",
        "This allows for a quick display of random images from that category.\n",
        "'''\n",
        "\n",
        "class display_images():\n",
        "  \n",
        "  def __init__(self, animal, directory):\n",
        "    self.animal = animal\n",
        "    self.directory = directory\n",
        "    self.animal_folder = os.path.join(self.directory + self.animal)\n",
        "    self.number_of_images = len(os.listdir(self.animal_folder))\n",
        "    print(\"Total training \" + self.animal +  \" images: \", self.number_of_images)\n",
        "    \n",
        "  def numberOfTimes(self, number):\n",
        "    # List of image paths in the specified category\n",
        "    random_list = []\n",
        "    for index in range(number):\n",
        "        random_list.append(np.random.randint(0,self.number_of_images))\n",
        "    \n",
        "    # Creates a list based on randomly picked images\n",
        "    self.animal_folder_images = [os.path.join(self.animal_folder, os.listdir(self.animal_folder)[image_index]) \n",
        "                                 for image_index in random_list]\n",
        "\n",
        "    for i, file_path in enumerate(self.animal_folder_images):\n",
        "      file_name = file_path[file_path.rfind(\"\\\\\") + 1:]\n",
        "      image_one = mpimg.imread(file_path)\n",
        "      plt.imshow(image_one)\n",
        "      plt.axis('Off')\n",
        "      #plt.title(file_name, loc='center')\n",
        "      plt.show()\n",
        "\n",
        "display_images(\"wolf\", training_directory).numberOfTimes(4)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzwqYPgeObue",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_img = Input(shape=(150, 150, 3))\n",
        "\n",
        "layer_1 = Conv2D(16, (3,3), activation='relu')(input_img)\n",
        "layer_2 = Conv2D(32, (3,3), activation='relu')(layer_1)\n",
        "layer_3 = MaxPooling2D((2,2))(layer_2)\n",
        "\n",
        "layer_4 = Conv2D(64, (3,3), activation='relu')(layer_3)\n",
        "layer_5 = MaxPooling2D((2,2))(layer_4)\n",
        "    \n",
        "### 1st layer\n",
        "layer_1_1_inception = Conv2D(20, (1,1), padding='same', activation='relu')(layer_5)\n",
        "layer_1_2_inception = MaxPooling2D((2,2), strides=(1,1), padding='same')(layer_5)\n",
        "layer_1_3_inception = Conv2D(12, (1,1), padding='same', activation='relu')(layer_5)\n",
        "layer_1_4_inception = MaxPooling2D((3,3), strides=(1,1), padding='same')(layer_5)\n",
        "layer_1_5_inception = Conv2D(12, (1,1), padding='same', activation='relu')(layer_5)\n",
        "\n",
        "### 2nd layer\n",
        "layer_2_1_inception = Conv2D(12, (1,3), padding='same', activation='relu')(layer_1_1_inception)\n",
        "layer_2_2_inception = Conv2D(24, (1,1), padding='same', activation='relu')(layer_1_2_inception)\n",
        "layer_2_3_inception = Conv2D(12, (1,5), padding='same', activation='relu')(layer_1_3_inception)\n",
        "layer_2_4_inception = Conv2D(24, (1,1), padding='same', activation='relu')(layer_1_4_inception)\n",
        "layer_2_5_inception = Conv2D(12, (1,3), padding='same', activation='relu')(layer_1_5_inception)\n",
        "\n",
        "### 3rd layer\n",
        "layer_3_1_inception = Conv2D(12, (3,1), padding='same', activation='relu')(layer_2_1_inception)\n",
        "layer_3_2_inception = Conv2D(12, (5,1), padding='same', activation='relu')(layer_2_3_inception)\n",
        "layer_3_3_inception = Conv2D(12, (3,1), padding='same', activation='relu')(layer_2_5_inception)\n",
        "\n",
        "mid_1 = tf.keras.layers.concatenate([layer_3_1_inception, layer_2_2_inception,\n",
        "                                     layer_3_2_inception, layer_2_4_inception,\n",
        "                                     layer_3_3_inception], axis = 3)\n",
        "\n",
        "layer_6 = Conv2D(84, (3,3), activation='relu')(mid_1)\n",
        "layer_7 = MaxPooling2D((2,2))(layer_6)\n",
        "\n",
        "layer_8 = Conv2D(96, (3,3), activation='relu')(layer_7)\n",
        "layer_9 = MaxPooling2D((2,2))(layer_8)\n",
        "\n",
        "### 4st layer\n",
        "layer_4_1_inception = Conv2D(24, (1,1), padding='same', activation='relu')(layer_9)\n",
        "layer_4_2_inception = MaxPooling2D((2,2), strides=(1,1), padding='same')(layer_9)\n",
        "layer_4_3_inception = Conv2D(24, (1,1), padding='same', activation='relu')(layer_9)\n",
        "\n",
        "### 5th layer\n",
        "layer_5_1_inception = Conv2D(24, (3,3), padding='same', activation='relu')(layer_4_1_inception)\n",
        "layer_5_2_inception = Conv2D(16, (1,1), padding='same', activation='relu')(layer_4_2_inception)\n",
        "layer_5_3_inception = Conv2D(24, (1,3), padding='same', activation='relu')(layer_4_3_inception)\n",
        "layer_5_4_inception = Conv2D(24, (3,1), padding='same', activation='relu')(layer_4_3_inception)\n",
        "\n",
        "### 5th layer\n",
        "layer_6_1_inception = Conv2D(24, (1,3), padding='same', activation='relu')(layer_5_1_inception)\n",
        "layer_6_2_inception = Conv2D(24, (3,1), padding='same', activation='relu')(layer_5_1_inception)\n",
        "\n",
        "mid_2 = tf.keras.layers.concatenate([layer_5_2_inception, layer_5_3_inception,\n",
        "                                     layer_5_4_inception, layer_6_1_inception,\n",
        "                                     layer_6_2_inception], axis = 3)\n",
        "\n",
        "flat_1 = Flatten()(mid_2)\n",
        "\n",
        "dense_1 = Dense(600, activation='relu')(flat_1)\n",
        "dense_2 = Dense(300, activation='relu')(dense_1)\n",
        "dense_3 = Dense(150, activation='relu')(dense_2)\n",
        "output = Dense(30, activation='softmax')(dense_3)\n",
        "\n",
        "my_model = Model([input_img], output)\n",
        "\n",
        "plot_model(my_model,\n",
        "           to_file = google_drive_location + '/InceptionModel.png',\n",
        "           show_shapes=True,\n",
        "           show_layer_names=True)\n",
        "\n",
        "# Print the model summary\n",
        "my_model.summary()\n",
        "\n",
        "def list_layers():\n",
        "    first_five = my_model.layers[: 8]\n",
        "    #last_five = my_model.layers[-5 :]\n",
        "    for layer in first_five:\n",
        "        class_of_layer = str(layer)[0 : str(layer).index(\" \")]\n",
        "        print(class_of_layer[class_of_layer.rfind('.') + 1 : ] + \" - \" + layer.name)\n",
        "\n",
        "a = list_layers()\n",
        "\n",
        "my_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lH9KR1nRNw0Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class visualization_by_layer():\n",
        "    \n",
        "    def __init__(self, animal):\n",
        "        # Creates a list of every animal in the specified folder\n",
        "        self.path = training_directory + animal\n",
        "        self.all_the_data = []\n",
        "        for image_id in os.listdir(self.path):\n",
        "            if os.path.isfile(self.path + \"/\" + image_id):\n",
        "                self.all_the_data.append(image_id)\n",
        "        # Randomly chooses an animal in the aggregated file paths\n",
        "        img_path = random.choice(self.all_the_data)\n",
        "        img = load_img(self.path + \"/\" + img_path, target_size=(150, 150))\n",
        "        x = img_to_array(img)\n",
        "        x = x.reshape((1,) + x.shape)\n",
        "        x /= 255.0\n",
        "        \n",
        "        # Avoids the input layer as part of the outputs\n",
        "        successive_layers = [layer for layer in my_model.layers[0:] if not layer.name.startswith('input')]\n",
        "        successive_outputs = [layer.output for layer in successive_layers]\n",
        "        visualization_model = tf.keras.models.Model(inputs = my_model.input, outputs = successive_outputs)\n",
        "        successive_feature_maps = visualization_model.predict(x)\n",
        "\n",
        "        position = 0\n",
        "        list_of_layers = []\n",
        "        for layer, feature_map in zip(successive_layers, successive_feature_maps):\n",
        "\n",
        "            if len(feature_map.shape) == 4:\n",
        "                \n",
        "                # Only for the conv/maxpool layers, not the fully-connected layers\n",
        "                # feature map shape (1, size, size, n_features)\n",
        "                n_features = feature_map.shape[-1]\n",
        "                size = feature_map.shape[1]\n",
        "            \n",
        "                # Tile images in this matrix\n",
        "                display_grid = np.zeros((size, size * n_features))\n",
        "                \n",
        "                # Postprocess the feature\n",
        "                for i in range(n_features):\n",
        "                    x  = feature_map[0, :, :, i]\n",
        "                    x -= x.mean()\n",
        "                    x /= x.std()\n",
        "                    x *=  64\n",
        "                    x += 128\n",
        "                    x  = np.clip(x, 0, 255).astype('uint8')\n",
        "                    # Tile each filter into a horizontal grid\n",
        "                    display_grid[:, i * size : (i + 1) * size] = x\n",
        "                \n",
        "                width = 20. / n_features\n",
        "                height = 10. / n_features\n",
        "                plt.rcParams.update({'figure.max_open_warning': 0})\n",
        "                plt.figure(figsize=(width * n_features, height))\n",
        "                \n",
        "                # Function that formats the title of the layer and provides\n",
        "                # cursory information based on the type of layer\n",
        "                def get_layer_information(layer_name):\n",
        "                    \n",
        "                    information = []\n",
        "                    title = ''\n",
        "                    \n",
        "                    layers_names = {\n",
        "                            'conv2d' : \"Convolutional 2D\",\n",
        "                            'conv3d' : \"Convolutional 3D\",\n",
        "                            'max_pooling' : \"Max Pooling\",\n",
        "                            'concatenate' : \"Concatenate\"\n",
        "                            }\n",
        "                    \n",
        "                    layers_properties = {\n",
        "                            'conv2d' : ['filters', 'kernel_size', 'strides'],\n",
        "                            'max_pooling' : ['pool_size', 'strides'],\n",
        "                            'concatenate' : ['axis']\n",
        "                            }\n",
        "                    \n",
        "                    for key in layers_names:\n",
        "                        if layer_name.startswith(key):\n",
        "                            name = layers_names.get(key, \"nothing\")\n",
        "                            information.append(name)\n",
        "                            title += name\n",
        "                            break;\n",
        "                    \n",
        "                    for key in layers_properties:\n",
        "                        if layer_name.startswith(key):\n",
        "                            prop = layers_properties.get(key, \"nothing\")\n",
        "                            for prop_type in prop:\n",
        "                                information.append(str(layer.get_config()[prop_type]))\n",
        "                            break;\n",
        "                            \n",
        "                    if key == 'conv2d':\n",
        "                        plt.title(title + \", Filters: \" + information[1] \n",
        "                                  + \", Kernel Size: \" + information[2]\n",
        "                                  + \", Strides: \" + information[3])\n",
        "                    elif key == 'max_pooling':\n",
        "                        plt.title(title + \", Pool Size: \" + information[1] \n",
        "                                  + \", Strides: \" + information[2])\n",
        "                    elif key == 'concatenate':\n",
        "                        plt.title(title + \", Axis: \" + information[1])\n",
        "                \n",
        "                get_layer_information(layer.name.lower())\n",
        "                \n",
        "                plt.grid(False)\n",
        "                # Displays the plot in the console\n",
        "                plt.imshow(display_grid, aspect='auto', cmap='viridis')\n",
        "                # Saves the output of every layer in the specified folder so they\n",
        "                # can be combined later\n",
        "                plt.savefig(visualizations + '/' + str(position) + '.png', bbox_inches='tight')\n",
        "                list_of_layers.append(visualizations + '/' + str(position) + '.png')\n",
        "                \n",
        "                position += 1\n",
        "\n",
        "        images = []\n",
        "        for each_layer in list_of_layers:\n",
        "            images.append(each_layer)\n",
        "        \n",
        "        widths, heights = zip(*(Image.open(each_image).size for each_image in images))\n",
        "        # Because of line 63, the width will be more or less the same for\n",
        "        # every output (depending on # of filters), however some are wider \n",
        "        # than others by a few pixels leading to black space behind the image,\n",
        "        # so the minimum width is taken instead of the maximum\n",
        "        min_width = min(widths)\n",
        "        total_height = sum(heights)\n",
        "        \n",
        "        new_im = Image.new('RGB', (min_width, total_height))\n",
        "        \n",
        "        y_offset = 0    \n",
        "        for im in images:\n",
        "          new_im.paste(Image.open(im), (0,y_offset))\n",
        "          y_offset += Image.open(im).size[1]\n",
        "        \n",
        "        # Removes the files that each contain the output of one layer\n",
        "        for each_file in os.listdir(visualizations):\n",
        "            if os.path.isfile(visualizations + '/' + each_file):\n",
        "                os.remove(visualizations + '/' + each_file)\n",
        "            \n",
        "        new_im.save(visualizations + '/output_by_layers.jpg')\n",
        "            \n",
        "                \n",
        "visualization_by_layer(\"wolf\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqOfrO1wRqW9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d372b890-cac2-4eec-ba43-6bfa762fc196"
      },
      "source": [
        "# Rescaling and augementations for the training data\n",
        "training_datagen = ImageDataGenerator(\n",
        "        rescale = 1./255.,\n",
        "        rotation_range=40,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True)\n",
        "# Rescaling for the test data\n",
        "validation_datagen = ImageDataGenerator(rescale = 1./255.)\n",
        "  \n",
        "# Training and test generators label data based on the folder name\n",
        "train_generator = training_datagen.flow_from_directory(\n",
        "        # specify the output size and type of classification (binary, category, etc)\n",
        "        training_directory,\n",
        "        batch_size = 26,\n",
        "        target_size=(150,150),\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "        testing_directory,\n",
        "        batch_size = 26,\n",
        "        target_size=(150,150),\n",
        "        class_mode='categorical')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 10410 images belonging to 30 classes.\n",
            "Found 2600 images belonging to 30 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkDKp01IRw2w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "    \n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        \n",
        "        if(logs.get('acc')>callback_cutoff_accuracy):\n",
        "            self.model.save_weights(external_drive_location + \"\\\\V3_Parthiv_Attempt_1.h5\")\n",
        "            print(\"\\nReached 60% accuracy so cancelling training!\")\n",
        "            self.model.stop_training = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOxVMpBgR2eY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = my_model.fit_generator(\n",
        "train_generator,\n",
        "validation_data = validation_generator,\n",
        "steps_per_epoch = 50,\n",
        "epochs = 20,\n",
        "validation_steps = 50,\n",
        "verbose = 1,\n",
        "callbacks=[myCallback()])\n",
        "    \n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6B6eQ_ICu08",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  path = fn\n",
        "  img = image.load_img(path, target_size=(150, 150))\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "\n",
        "  images = np.vstack([x])\n",
        "  classes = model.predict(images, batch_size=10)\n",
        "  print(fn)\n",
        "  print(classes)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}